---
title: "Using R for Data Analysis"
subtitle: ""
author: "Elizabeth Davis"
institute: "San Diego Zoo Global"
date: "2019/05/08 (updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    css: [default, rladies, rladies-fonts]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include = FALSE}
library(tidyverse)
library(MASS)
options(htmltools.dir.version = FALSE)
```


```{css, echo=FALSE}
/* custom.css */
.left-code {
  color: #777;
  width: 38%;
  height: 92%;
  float: left;
}
.right-plot {
  width: 60%;
  float: right;
  padding-left: 1%;
}
.plot-callout {
  height: 225px;
  width: 450px;
  bottom: 5%;
  right: 5%;
  position: absolute;
  padding: 0px;
  z-index: 100;
}
.plot-callout img {
  width: 100%;
  border: 4px solid #23373B;
}
```

---
# Previously, we learned the basics of R

--

## But you may have gone away still feeling like you don't know how to navigate in R "space"

--

### In these next few sections, I'll go through *how to use R scripts effectively*, *how to understand R Studio*, and *how to read an R helpfile*, which should help you with feeling more confident in using R.

---
# How to use R Scripts effectively

--

## Go ahead and open an R script on your R studio. It will be the icon in the top left of your console. It looks like this:

![R Script icon](images/r-script-icon.png)

---
# R Scripts are where you keep your code that you will use for your *data analysis*.

--

## It is a record of what you have done, so that you can replicate it in the future. <sup>1</sup>

--

### This is VERY important because projects sometimes take multiple days, if not weeks.

.footnote[[1] "making your analyses something that can be re-run easily as needed"]

---
# R Scripts are where you keep your code, so they are also where you should include *comments*, i.e. a way of explaining to others/your future self what you have done

---

## The most important thing is to use them as though *you may be hit on the head and lose your memory at any moment*. Be VERY clear about your process and why you are doing what you are.

---

![R Script example](images/r-script-example.png)

---

#How to use R studio

--

## R Studio has a lot of in-built tools that help with effective coding.

--

## For example, R will automatically close parantheses and quotation marks for you; however, you need to be careful that this doesn't cause mistakes.

--

## R Studio will also show you when you make a mistake in your R Script, through red lines underlining code and a red "X"

---

![R Script example of errors](images/r-script-errors.png)
--

### You can see here where R is telling you that your code is faulty.

--

### You can also see that R Studio will color code differently according to its attribute: a different color for non-code "objects", for comments, and for "significant" commands like telling R which library to use.

---

# Error Codes

--
<img src="images/skipping-falling.gif", width = "100%">

---
class: center, middle

## "Start associating error messages with joy because it probably means you are about to learn something!"

---

# What do to do when you get an error code

--

## Read the code. This seems self-explanatory but it is where you can gain some understanding of what went wrong. 

--

## As an example, what happens if you type "a" and press enter?

--

![Error example](images/error.png)
---
![Error example](images/error.png)

--

## This message has **three** parts

--

### 1) It tells us that it is an error

--

### 2) The location of the error, which is object "a"

--

### 3) The problem this mistake caused: there is no object a, because I haven't created it!

---

# Sometimes errors are difficult to understand

--

## If you can't understand the error message immediately, then you have several options:

--

### 1) Check out the help file for the function/command you are using, if applicable

--

### 2) Google it!

--

### 3) Ask for help from Stack Overflow (bearing in mind that it can be challenging) or from R-Ladies (if you are a woman- sorry guys!)

---

# Checking out the help file

--

## The help file can be challenging to understand, so Googling may be the easiest option for you. However, it is important to be familiar with R helpfiles.

---

![R help first bit](images/r-help-first-bit.png)

---

![R help second bit](images/r-help-second-bit.png)
---

# Using R for data analysis

--

## "Statistics [and data analysis] is a problem-solving and decision-making process that is fundamental to scientific inquiry and essential for making sound decisions."

--

### Requires **critical thinking** (and practice!)

---
class: center, middle

## I'm going to show you this process through working *backwards*: I'll show you results, findings, and interpretation, and from there show you how I did the data analysis. 

---

# Land use in the Greater Mekong Region: 2012
---
![land use km](images/land-use-km.png)
---
![land use percent](images/land-use-percent.png)
---

#Overall difference between the countries

```{r difference, tidy = TRUE}
library(formatR)
land.indicators.2012.km <- read.csv("land-indicators-2012-km.csv")
land.indicators.2012.percent <- read.csv("land-indicators-2012-percent.csv")
#Land use by km2
summary(aov(land.indicators.2012.km$Amount ~ land.indicators.2012.km$Country))

#Land use by percent
summary(aov(land.indicators.2012.percent$Amount ~ land.indicators.2012.percent$Country))
```
---

#Where is the difference between countries found?

```{r}
TukeyHSD(aov(land.indicators.2012.percent$Amount ~ land.indicators.2012.percent$Country))
```
---

## What does this tell us?

--

```{r demo, highlight.output = 13}

TukeyHSD(aov(land.indicators.2012.percent$Amount ~ land.indicators.2012.percent$Country))

```

---
class: center, inverse, middle

##From this we can interpret that there isn't much of a difference between the countries. There is, however a significant difference between Thailand and Laos, for **what their land is used for**. In general, Laos has used a lot less of their land for agriculture, compared to the other countries but especially compared to Thailand.

---

#How did I get to this point?

--

##First, by looking at the data as it was in the `.csv` file.
![original data](images/original-data.png)

---

##Because this is a pretty simple dataset, I decided to do a basic analysis where I try to understand the difference between the countries. I decided to start by **visualizing the data**, using `ggplot2`. (Hopefully you all remember how to use it!)

---
### However, you may have noticed that our data is not easy to use for creating a `ggplot`. I cheated and went to the .csv file to turn my data into a format that could be read by `ggplot`, specifically, where all of the variables are columns.

--
![km2 data](images/km2-data.png)

---
### BUT, it wasn't as easy as doing this for the whole dataset. When I looked at the data, the data was represented in different formats, *kilometers squared* and *percent*. So, I had to create two datasets.


.pull-left[
###**km2**
![km2 data](images/km2-data.png)
]

.pull-right[
###**percent**
![percent data](images/percent-data.png)
]
---
class: center, middle

## Hopefully you can see here why we couldn't plot these together. Kilometers squared is on a much larger scale than percent, i.e. 200,000 versus 35.

---

To plot this data, I used the following code. Again, this took me some trial and error to get it right for both graphs. 

```{r graph,fig.show="hide", message = FALSE, warning = FALSE}
require(tidyverse)
require(scales)
ggplot(land.indicators.2012.km, aes(x = Country, y = Amount, fill = Country)) +
  geom_bar(stat = "identity") + 
  theme_bw() +
  scale_fill_viridis_d() +
  facet_wrap(~Land.Use.Type) + 
  scale_y_continuous(name="Country", labels = comma) +
  ggtitle("Land Use Types Between Countries (km2)") +
  theme(text = element_text(size = 20)) 

ggplot(land.indicators.2012.percent, aes(x = Country, y = Amount, fill = Country)) +
  geom_bar(stat = "identity") + 
  theme_bw() +
  scale_fill_viridis_d() +
  facet_wrap(~Land.Use.Type) + 
  scale_y_continuous(name="Country", labels = comma) +
  ggtitle("Land Use Types Between Countries (%)") +
  theme(text = element_text(size = 20)) +
  scale_x_discrete(limits=c("Thailand","Vietnam","Cambodia", "Myanmar", "Laos"))
```

---

![land use km](images/land-use-km.png)

---

![land use percent](images/land-use-percent.png)

---

## As you saw, after visualizing these graphs, I decided to perform an ANOVA on *country* and *amount* (of km2/percent of land used for other purposes), to see whether the country differences seen are significant.

### The ANOVA for percent was significant, so I performed the follow-up test of TUKEY's HSD to determine where the difference was, and found that Thailand and Laos significantly differed in the percent of their land used for agriculture. 

---

## And that's it! There are probably all kinds of better and more interesting things that could be done with that data, but that will do for now.

---

background-image: url("images/mountain.jpg")
class: center, middle, inverse

## Let's take a break

---

# Tidying our data with `dplyr`

--
class: center, middle

## `dplyr` is a package within the `tidyverse`. It is widely used in R data analysis because it is quick and efficient at cleaning and sorting data.


<br><br><br><br><br><br><br><br>

#### Disclaimer: I am not very good at using `dplyr` myself! So we will both be learning.

---
class: center, middle

## First, we will load the `tidyverse` package (install it if you haven't already).

### We’re going to learn some of the most common dplyr functions: `select()`, `filter()`, `mutate()`, `group_by()`, and  `summarise()`.

---

# `select()`

--

## As the name implies, this is where we *select* the columns that we want to keep in a data frame.

--

### But first, you'll need to load the data. Do the following:

```{r}
library(nycflights13)
flights
```

#### And take a look at our data using all of the tools I taught you in the first course (`head`, `summary`, and one you may not have used previously: `str`).

---

# Using `select()` on your data

--
  
### The first argument to this function is the data frame (which `dplyr` calls a tibble), and the subsequent arguments are the columns to keep.

### For our data in `flights`, let's use `select` to choose some columns to keep.

```{r select}
dplyr::select(flights, year, month, day)
```


---

# Easy, right? Now let's choose some rows to work with using `filter`.

```{r filter}
dplyr::filter(flights, month == 1, day == 1)
```

---

## This lets us filter our data so that it only shows flights on January 1st.

--

### **Remember, if you want to use these commands to create a new dataframe, you need to apply these commands to an object, i.e.:

--

```{r object}
jan_first_flights <- dplyr::filter(flights, month == 1, day == 1) #<<
```

---

# But what if you want to use `select` AND `filter`?

--

## We use something called **pipes**. Pipes look like this ` %>% `. They take the output of one command and put it directly into the next.

--

### Example:

```{r pipe}
flights %>%
  dplyr::filter(month == 1) %>%
  dplyr::select(year, month, day, dep_delay)
```

---
Class: center, middle

## We perform these commands as part of something called *data carpentry*, i.e. getting your data useable in analysis and visualization. The more you work with data, the more you'll understand what these commands are doing and how they'll help you, down the line.

---

# Exercise

--

## Using pipes, subset `flights` to include rows where the year is 2013 and keep only the columns year,  month, and dep_delay.

### How many rows are in that tibble?

HINT: You can use the nrow() function to find out how many rows are in a tibble.

---

# `mutate`

## Frequently you’ll want to create new columns based on the values in existing columns, for example to do unit conversions or find the ratio of values in two columns. For this we’ll use `mutate()`

--
### Let's create a new column of the flight duration. We can do this by using mutate and subtracting `arr_time` (arrival time) from the `dep_time` (departure time). 

```{r flight duration}
flights %>%
  mutate(duration = arr_time - dep_time)
```

---

# Split-apply-combine data analysis and the `summarize()` function

--

## Many data analysis tasks can be approached using the “split-apply-combine” paradigm: 

1. Split the data into groups 

--

2. Apply some analysis to each group

--

3. And then combine the results. 

--

`dplyr` makes this very easy through the use of the `group_by()` function, which splits the data into groups.

---

## When the data is grouped in this way `summarize()` can be used to collapse each group into a single-row summary. `summarize()` does this by applying an aggregating or summary function to each group. For example, if we wanted to group by month and find the number of rows of data for each year, we would do:

--

```{r group}
flights %>%
  group_by(month) %>%
  summarize(n())
```

---

## Of course, that doesn't tell us much that is useful. Let's look at the mean departure delay for each month.

--

```{r flights mean}
flights %>%
  group_by(month) %>%
  summarize(mean_dep_delay = mean(dep_delay, na.rm = TRUE))
```

--

### The `na.rm` here is where we tell R to ignore any missing data which usually is shown as "NA". If we don't use this command and we have missing data, R will return an error.

---

## You can also group by multiple columns, which is very handy!

--

```{r multiple}
flights %>%
  group_by(carrier, month) %>%
  summarize(mean_dep_delay = mean(dep_delay, na.rm = TRUE))
```

---

## You can also use summarize on multiple variables (columns, for our flights data). For our example, let's look at the mean delay as well as the minimum value for departure time:

--

```{r summarize multiple}
flights %>%
  group_by(carrier, month) %>%
  summarize(mean_dep_delay = mean(dep_delay, na.rm = TRUE),
            min_generation = min(dep_time, na.rm = TRUE))
```

---

# Long to wide and wide to long

--

## Our flights data is currently in "long" format, which is usually (but not always!!) how you are going to want your data to be, for the kinds of data analyses you'll be doing. Sometimes, you want to turn your data wide.

--

## To do this, we can make our data wide and compare carriers and their departure delays. This is again easy to do with `dplyr`, using the `spread` function.

--

```{r spread}
library(nycflights13)
flights_wide <- flights %>%
  tidyr::spread(carrier, dep_delay)

flights_wide
```

---

## What is happening with this command?

--

### `spread` requires you tell it the name of the column which contains values that will be the column names in your new data set - a so called “key” column. You also tell it which column contains the relevant numbers - the “values” column.

--

### In our example here, we see that there are quitea lot of NAs, so this is not a sensible way to organize our data.

---

# As I told you a few minutes ago, you guys will usually be working with "long" data. So, you will want to know how to transform your "wide" data into this format.

--

## For this, you will use the `gather` function.

--

### In this case you specify what you want the name of the new key column to be, what you want the name of the new values column to be, and then you can either specify which columns are to be gathered up (which can be tedious if there are a lot or they are spread) or you can specify which columns you want to exclude. 

--

I will show you an example where we *exclude* a column.

---

```{r long}
# First we create a dataset called stocks
stocks <- tibble(
  time = as.Date('2009-01-01') + 0:9,
  X = rnorm(10, 0, 1),
  Y = rnorm(10, 0, 2),
  Z = rnorm(10, 0, 4)
)

#Then we use gather to change the wide data into long format
stocks %>% gather("stock", "price", -time)

```

---

class: center, middle

# And that's it! You now know the basics of data carpentry with `dplyr`. 

--

## Of course, R being R there is always more to learn, so be sure to check out the "Helpful R Sites" document to see examples of more tutorials.

---

class: center, middle, inverse

# Acknowledgements

### Grateful thanks to everyone on Twitter and especially Aleeza Gerstein at the University of Manitoba for kindly sharing her materials.
